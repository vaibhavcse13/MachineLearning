{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2999.16598031\n",
      "[  1.23301013  31.71316744   1.5611327   -0.4139157 ]\n",
      "0.810116191962\n",
      "47.6163509082\n",
      "4162.60690316\n",
      "64.5182679802\n",
      "-1113.58868579\n",
      "[  0.09194471  48.52612838   1.41391838   0.83028445]\n",
      "0.831541885719\n",
      "55.1481704887\n",
      "4155.20149167\n",
      "64.4608523964\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql as  db\n",
    "import pandas.io.sql as psql\n",
    "\n",
    "con = db.connect('localhost','root' ,'vaibhav','testsave')\n",
    "\n",
    "def Build_Ann_Data_Set(state):\n",
    "    sql = \"SELECT * FROM Delhi %s\"%state\n",
    "    data = psql.read_sql(sql, con )\n",
    "    feat = ['Year', 'Ann_Wdf' , 'Ann_Mtemp','Ann_Cloud']\n",
    "    x = data[feat]\n",
    " \n",
    "    tar = np.array(data['Annual_Rain'])\n",
    "    y = pd.Series(tar)\n",
    "    return x,y\n",
    "\n",
    "def Build_Mon_Data_Set(state):\n",
    "    sql = \"SELECT * FROM %s \"%state\n",
    "    data = psql.read_sql(sql, con )\n",
    "    #data = pd.read_excel(\"G:/Gzb/Ugzb.xlsx\")\n",
    "    feat = ['Year', 'Jun_Sep_Wdf' , 'Jun_Sep_Mtemp','Jun_Sep_Cloud']\n",
    "    x = data[feat]\n",
    " \n",
    "    tar = np.array(data['Jun_Sep_Rain'])\n",
    "    y = pd.Series(tar)\n",
    "    return x,y\n",
    "\n",
    "def AnnAnalysis():\n",
    "    x,y = Build_Ann_Data_Set(\"Delhi\")\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x ,y ,test_size=20, random_state=14)\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    lreg = LinearRegression()\n",
    "    lreg.fit(x_train, y_train )\n",
    "    ypred = lreg.predict(x_test)\n",
    "    print(lreg.intercept_)\n",
    "    print(lreg.coef_)\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    print(r2_score(y_test, ypred))\n",
    "    from sklearn import metrics\n",
    "    print(metrics.mean_absolute_error(y_test , ypred))\n",
    "    print(metrics.mean_squared_error(y_test , ypred))\n",
    "    print(np.sqrt(metrics.mean_squared_error(y_test , ypred)))\n",
    "    \n",
    "def MonAnalysisDelhi():\n",
    "    x,y = Build_Mon_Data_Set(\"Delhi\")\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x ,y ,test_size=20, random_state=1)\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    lreg = LinearRegression()\n",
    "    lreg.fit(x_train, y_train )\n",
    "    ypred = lreg.predict(x_test)\n",
    "    print(lreg.intercept_)\n",
    "    print(lreg.coef_)\n",
    "    from sklearn.metrics import r2_score\n",
    "    print(r2_score(y_test, ypred))\n",
    "    from sklearn import metrics\n",
    "    print(metrics.mean_absolute_error(y_test , ypred))\n",
    "    print(metrics.mean_squared_error(y_test , ypred))\n",
    "    print(np.sqrt(metrics.mean_squared_error(y_test , ypred)))\n",
    "    \n",
    "AnnAnalysis()\n",
    "MonAnalysisDelhi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 756.30638366]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymysql as  db\n",
    "import pandas.io.sql as psql\n",
    "con = db.connect('localhost','root' ,'vaibhav','NewSave')\n",
    "\n",
    "def Build_Data_Set(state):\n",
    "    sql = \"SELECT * FROM %s \"%state\n",
    "    data = psql.read_sql(sql, con )\n",
    "    feat = ['Year', 'Ann_Wdf' , 'Ann_Mtemp','Ann_Cloud']\n",
    "    x = data[feat]\n",
    " \n",
    "    tar = np.array(data['Annual_Rain'])\n",
    "    y = pd.Series(tar)\n",
    "    return x,y\n",
    "\n",
    "def Analysis():\n",
    "    x,y = Build_Data_Set(\"Delhi\")\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x ,y ,test_size=20, random_state=1)\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    lreg = LinearRegression()\n",
    "    z = lreg.fit(x_train, y_train )\n",
    "    ypred = z.predict(x_test)\n",
    "    #print(z.intercept_)\n",
    "    #print(z.coef_)\n",
    "    from sklearn.metrics import r2_score\n",
    "    #print(r2_score(y_test, ypred))\n",
    "    #from sklearn import metrics\n",
    "    #print(metrics.mean_absolute_error(y_test , ypred))\n",
    "    #print(metrics.mean_squared_error(y_test , ypred))\n",
    "    #print(np.sqrt(metrics.mean_squared_error(y_test , ypred)))\n",
    "    return z\n",
    "\n",
    "\n",
    "def Build_Cloud(yr):\n",
    "    sql = \"SELECT Ann_Cloud ,Year FROM Chennai \"\n",
    "    #data = psql.read_sql(sql, con )\n",
    "    cloud_data = psql.read_sql(sql, con )\n",
    "    x = cloud_data[['Year']]\n",
    "    y = cloud_data[['Ann_Cloud']]\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x ,y ,test_size=20, random_state=1)\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    cldreg = LinearRegression()\n",
    "    cldreg.fit(x_train, y_train )\n",
    "    ypred = cldreg.predict(x_test)\n",
    "    #print(cldreg.intercept_)\n",
    "    #print(cldreg.coef_)\n",
    "    from sklearn.metrics import r2_score\n",
    "    #print(r2_score(y_test, ypred))\n",
    "    from sklearn import metrics\n",
    "    #print(metrics.mean_absolute_error(y_test , ypred))\n",
    "    #print(metrics.mean_squared_error(y_test , ypred))\n",
    "    #print(np.sqrt(metrics.mean_squared_error(y_test , ypred)))\n",
    "    c = cldreg.predict(yr)\n",
    "    return c\n",
    "    \n",
    "    \n",
    "def Temp_Analysis(yr):\n",
    "    sql = \"SELECT Ann_Mtemp ,Year FROM Delhi \"\n",
    "    #data = psql.read_sql(sql, con )\n",
    "    cloud_data = psql.read_sql(sql, con )\n",
    "    x = cloud_data[['Year']]\n",
    "    y = cloud_data[['Ann_Mtemp']]\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x ,y ,test_size=20, random_state=11)\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    treg = LinearRegression()\n",
    "    treg.fit(x_train, y_train )\n",
    "    ypred = treg.predict(x_test)\n",
    "    #print(treg.intercept_)\n",
    "    #print(treg.coef_)\n",
    "    from sklearn.metrics import r2_score\n",
    "    #print(r2_score(y_test, ypred))\n",
    "    from sklearn import metrics\n",
    "    #print(metrics.mean_absolute_error(y_test , ypred))\n",
    "    #print(metrics.mean_squared_error(y_test , ypred))\n",
    "    #print(np.sqrt(metrics.mean_squared_error(y_test , ypred)))\n",
    "    #yr = float(input(\"Enter year\"))\n",
    "    t = treg.predict(yr)\n",
    "    \n",
    "    return t\n",
    "    \n",
    "def Wet_Day_Analysis(yr):\n",
    "    sql = \"SELECT Ann_Wdf ,Year FROM Delhi \"\n",
    "    #data = psql.read_sql(sql, con )\n",
    "    cloud_data = psql.read_sql(sql, con )\n",
    "    x = cloud_data[['Year']]\n",
    "    y = cloud_data[['Ann_Wdf']]\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x ,y ,test_size=20, random_state=10)\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    wdfreg = LinearRegression()\n",
    "    wdfreg.fit(x_train, y_train )\n",
    "    ypred = wdfreg.predict(x_test)\n",
    "    #print(wdfreg.intercept_)\n",
    "    #print(wdfreg.coef_)\n",
    "    from sklearn.metrics import r2_score\n",
    "    #print(r2_score(y_test, ypred))\n",
    "    from sklearn import metrics\n",
    "    #print(metrics.mean_absolute_error(y_test , ypred))\n",
    "    #print(metrics.mean_squared_error(y_test , ypred))\n",
    "    #print(np.sqrt(metrics.mean_squared_error(y_test , ypred)))\n",
    "    #yr = float(input(\"Enter year\"))\n",
    "    t = wdfreg.predict(yr)\n",
    "    return t \n",
    "\n",
    "def Prediction(year):\n",
    "    z = Analysis()\n",
    "    #print(z.coef_)\n",
    "    #print(z.intercept_)\n",
    "    p = Build_Cloud(year)\n",
    "    q = Wet_Day_Analysis(year)\n",
    "    r = Temp_Analysis(year)\n",
    "    \n",
    "    \n",
    "    x = np.array([year , q,  r, p])\n",
    "    t = x.reshape(1,-1)\n",
    "    y = z.predict(t)\n",
    "    print(y)\n",
    "#to test this script remove the comment and enter the year \n",
    "#Prediction(*Enter Year*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
